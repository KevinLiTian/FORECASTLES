{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "nET0YeAqHErJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_path = \"/content/drive/MyDrive/shelter_neighbourhood_features_pca.csv\"\n",
        "non_pca_data_path = \"/content/shelter_neighbourhood_features.csv\"\n"
      ],
      "metadata": {
        "id": "1cImZVFjQejN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def load_data(include_capacity=True):\n",
        "    occupancy_data_2023 = pd.read_csv(\"../data/occupancy/Daily_shelter_overnight_occupancy.csv\", low_memory=False)\n",
        "    occupancy_data_2021 = pd.read_csv(\"../data/occupancy/daily-shelter-overnight-service-occupancy-capacity-2021.csv\",\n",
        "                                      low_memory=False)\n",
        "    occupancy_data_2022 = pd.read_csv(\"../data/occupancy/daily-shelter-overnight-service-occupancy-capacity-2022.csv\",\n",
        "                                      low_memory=False)\n",
        "    occupancy_data_2022['OCCUPANCY_DATE'] = pd.to_datetime(occupancy_data_2022['OCCUPANCY_DATE'],\n",
        "                                                           format='%y-%m-%d').dt.strftime('%Y-%m-%d')\n",
        "    occupancy_data_2021['OCCUPANCY_DATE'] = pd.to_datetime(occupancy_data_2021['OCCUPANCY_DATE'],\n",
        "                                                           format='%y-%m-%d').dt.strftime('%Y-%m-%d')\n",
        "    all_shelter_data = pd.concat([occupancy_data_2023, occupancy_data_2022, occupancy_data_2021])\n",
        "    all_shelter_data['OCCUPANCY_DATE'] = pd.to_datetime(all_shelter_data['OCCUPANCY_DATE'], format='%Y-%m-%d')\n",
        "    toronto_data = all_shelter_data[all_shelter_data[\"LOCATION_CITY\"] == \"Toronto\"]\n",
        "    toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
        "    toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
        "    toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n",
        "    drop_cols = ['_id', 'ORGANIZATION_ID', 'ORGANIZATION_NAME', 'SHELTER_ID', 'SHELTER_GROUP',\n",
        "                 'LOCATION_ID', 'LOCATION_NAME', 'LOCATION_ADDRESS', 'LOCATION_CITY', 'LOCATION_PROVINCE', 'PROGRAM_ID',\n",
        "                 'PROGRAM_NAME', 'OVERNIGHT_SERVICE_TYPE', 'PROGRAM_AREA', 'CAPACITY_FUNDING_BED',\n",
        "                 'OCCUPIED_BEDS', 'UNOCCUPIED_BEDS', 'CAPACITY_FUNDING_ROOM', 'OCCUPIED_ROOMS', 'UNOCCUPIED_ROOMS',\n",
        "                 'OCCUPANCY_RATE_ROOMS', \"OCCUPANCY_RATE_BEDS\", 'UNAVAILABLE_BEDS','UNAVAILABLE_ROOMS'\n",
        "                 ]\n",
        "    if not include_capacity:\n",
        "        drop_cols.extend(['CAPACITY_ACTUAL_BED', 'CAPACITY_ACTUAL_ROOM'])\n",
        "    toronto_data_dr = toronto_data.drop(columns=drop_cols)\n",
        "    toronto_data_dr_nan = toronto_data_dr[toronto_data_dr[\"PROGRAM_MODEL\"].notna()]\n",
        "    # Creating list of dummy columns\n",
        "    to_get_dummies_for = ['SECTOR']\n",
        "\n",
        "    # Creating dummy variables\n",
        "    toronto_data_dr_nan = pd.get_dummies(data=toronto_data_dr_nan, columns=to_get_dummies_for)\n",
        "\n",
        "    # Mapping overtime and attrition\n",
        "    dict_prog_mod = {'Emergency': 1, 'Transitional': 0}\n",
        "    dict_cap_type = {'Bed Based Capacity': 1, 'Room Based Capacity': 0}\n",
        "\n",
        "    toronto_data_dr_nan['prog_mod'] = toronto_data_dr_nan[\"PROGRAM_MODEL\"].map(dict_prog_mod)\n",
        "    toronto_data_dr_nan['cap_type'] = toronto_data_dr_nan[\"CAPACITY_TYPE\"].map(dict_cap_type)\n",
        "    toronto_data_dr_nan = toronto_data_dr_nan.drop(columns=[\"PROGRAM_MODEL\", \"CAPACITY_TYPE\"])\n",
        "    toronto_data_dr_nan[\"postal_code\"] = toronto_data_dr_nan['LOCATION_POSTAL_CODE'].apply(lambda x: x.split(\" \")[0])\n",
        "    toronto_data_dr_nan[\"postal_code\"] = toronto_data_dr_nan[\"postal_code\"].astype('category')\n",
        "    toronto_data_dr_nan[\"postal_code_num\"] = pd.Categorical(toronto_data_dr_nan[\"postal_code\"]).codes\n",
        "    final_df = toronto_data_dr_nan.drop(columns=[\"postal_code\", \"LOCATION_POSTAL_CODE\", 'OCCUPANCY_DATE'])\n",
        "    occu_final_df = toronto_data_dr_nan.drop(columns=[\"postal_code\", \"LOCATION_POSTAL_CODE\"])\n",
        "    occu_final_df = occu_final_df[occu_final_df['YEAR']==2023]\n",
        "    final_df = final_df.fillna(value=0.0)\n",
        "    test = final_df[final_df['YEAR']==2023]\n",
        "    train = final_df[(final_df['YEAR']==2021) | (final_df['YEAR']==2022)]\n",
        "    train = train.drop(columns=['YEAR'])\n",
        "    test = test.drop(columns=['YEAR'])\n",
        "    X_train, X_test, y_train, y_test = train.drop(columns=['SERVICE_USER_COUNT']), test.drop(columns=['SERVICE_USER_COUNT']), train['SERVICE_USER_COUNT'], test['SERVICE_USER_COUNT']\n",
        "    sc = StandardScaler()\n",
        "\n",
        "    # Fit_transform on train data\n",
        "    X_train_scaled = sc.fit_transform(X_train)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "    # Transform on test data\n",
        "    X_test_scaled = sc.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_train.columns)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, occu_final_df\n",
        "\n",
        "\n",
        "class DefaultDataset(Dataset):\n",
        "    def __init__(self, data_x, data_y):\n",
        "        self.x = torch.from_numpy(data_x)\n",
        "        self.y = torch.from_numpy(data_y)\n",
        "        self.length = len(data_y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index].float(), self.y[index].float()\n",
        "\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, data_x, data_y, news_data, window=30):\n",
        "        self.x = torch.from_numpy(data_x)\n",
        "        self.y = torch.from_numpy(data_y)\n",
        "        self.length = len(data_y)-window+1\n",
        "        self.window = window\n",
        "        self.news_data = news_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.news_data[index:index+self.window], self.x[index:index+self.window].float(), self.y[index+self.window-1].float()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     X_train_scaled, X_test_scaled, y_train, y_test = load_data()\n",
        "#     train_dataset = DefaultDataset(X_train_scaled.to_numpy(), np.asarray(y_train))\n",
        "#     test_dataset = DefaultDataset(X_test_scaled.to_numpy(), np.asarray(y_test))\n",
        "#     # train_dataset = SequenceDataset(X_train_scaled.to_numpy(), np.log10(np.expand_dims(np.asarray(y_train), axis=-1)))\n",
        "#     # test_dataset = SequenceDataset(X_test_scaled.to_numpy(), np.log10(np.expand_dims(np.asarray(y_test), axis=-1)))\n",
        "\n",
        "#     x, y = train_dataset[10]\n",
        "#     print(x.shape, y.shape)\n",
        "\n",
        "#     train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "#     test_dataloader = DataLoader(dataset=test_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "#     print(f\"Training data batches {len(train_dataloader)}\")\n",
        "#     print(f\"Testing data batches {len(test_dataloader)}\")\n"
      ],
      "metadata": {
        "id": "UcmSc_MzEqvT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03_s3H3PHTRy",
        "outputId": "584c2d21-fedb-4280-b708-3f1bcce6b2ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(combined_data_path, low_memory=False)\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBhChuGbICFU",
        "outputId": "172be8e0-6f95-45d8-b046-3a196668e83a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 138240 entries, 0 to 138239\n",
            "Columns: 155 entries, _id to V118\n",
            "dtypes: float64(135), int64(5), object(15)\n",
            "memory usage: 163.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgNWukbZq49Y",
        "outputId": "e60504e9-28d7-4106-c8a8-fe190bbe8f0e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=138240, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"LOCATION_CITY\"]==\"Toronto\"].head(20)[[\"OCCUPANCY_DATE\", \"SHELTER_ID\", \"LOCATION_ID\", \"SECTOR\", \"PROGRAM_MODEL\", \"CAPACITY_TYPE\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "EKIi0UHdIiWP",
        "outputId": "1634e4d0-71cd-48bb-df49-4b56d6d6cf7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   OCCUPANCY_DATE  SHELTER_ID  LOCATION_ID       SECTOR PROGRAM_MODEL  \\\n",
              "5      2021-01-01          40       1051.0  Mixed Adult     Emergency   \n",
              "9      2021-01-01          22       1172.0          Men     Emergency   \n",
              "10     2021-01-01          22       1029.0          Men     Emergency   \n",
              "11     2021-01-01          22       1102.0          Men     Emergency   \n",
              "12     2021-01-01          39       1052.0     Families     Emergency   \n",
              "15     2021-01-01          53       1070.0     Families     Emergency   \n",
              "16     2021-01-01          23       1183.0  Mixed Adult     Emergency   \n",
              "17     2021-01-01          23       1184.0  Mixed Adult     Emergency   \n",
              "18     2021-01-01          23       1185.0  Mixed Adult     Emergency   \n",
              "19     2021-01-01          23       1186.0     Families     Emergency   \n",
              "20     2021-01-01          23       1186.0  Mixed Adult     Emergency   \n",
              "21     2021-01-01          60       1009.0          Men  Transitional   \n",
              "22     2021-01-01          83       1181.0  Mixed Adult     Emergency   \n",
              "24     2021-01-01           2       1065.0     Families     Emergency   \n",
              "25     2021-01-01           2       1065.0     Families     Emergency   \n",
              "26     2021-01-01           2       1066.0     Families     Emergency   \n",
              "27     2021-01-01           2       1066.0     Families     Emergency   \n",
              "28     2021-01-01           2       1067.0     Families     Emergency   \n",
              "29     2021-01-01          62       1011.0          Men  Transitional   \n",
              "31     2021-01-01          62       1011.0          Men  Transitional   \n",
              "\n",
              "          CAPACITY_TYPE  \n",
              "5    Bed Based Capacity  \n",
              "9   Room Based Capacity  \n",
              "10   Bed Based Capacity  \n",
              "11   Bed Based Capacity  \n",
              "12  Room Based Capacity  \n",
              "15  Room Based Capacity  \n",
              "16  Room Based Capacity  \n",
              "17  Room Based Capacity  \n",
              "18  Room Based Capacity  \n",
              "19  Room Based Capacity  \n",
              "20  Room Based Capacity  \n",
              "21   Bed Based Capacity  \n",
              "22  Room Based Capacity  \n",
              "24  Room Based Capacity  \n",
              "25   Bed Based Capacity  \n",
              "26  Room Based Capacity  \n",
              "27  Room Based Capacity  \n",
              "28  Room Based Capacity  \n",
              "29   Bed Based Capacity  \n",
              "31   Bed Based Capacity  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee4e30dc-4dd0-4842-b6db-d840d8f6b084\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OCCUPANCY_DATE</th>\n",
              "      <th>SHELTER_ID</th>\n",
              "      <th>LOCATION_ID</th>\n",
              "      <th>SECTOR</th>\n",
              "      <th>PROGRAM_MODEL</th>\n",
              "      <th>CAPACITY_TYPE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>40</td>\n",
              "      <td>1051.0</td>\n",
              "      <td>Mixed Adult</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>22</td>\n",
              "      <td>1172.0</td>\n",
              "      <td>Men</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>22</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>Men</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>22</td>\n",
              "      <td>1102.0</td>\n",
              "      <td>Men</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>39</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>53</td>\n",
              "      <td>1070.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>23</td>\n",
              "      <td>1183.0</td>\n",
              "      <td>Mixed Adult</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>23</td>\n",
              "      <td>1184.0</td>\n",
              "      <td>Mixed Adult</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>23</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>Mixed Adult</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>23</td>\n",
              "      <td>1186.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>23</td>\n",
              "      <td>1186.0</td>\n",
              "      <td>Mixed Adult</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>60</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>Men</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>83</td>\n",
              "      <td>1181.0</td>\n",
              "      <td>Mixed Adult</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>1066.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>1066.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>2</td>\n",
              "      <td>1067.0</td>\n",
              "      <td>Families</td>\n",
              "      <td>Emergency</td>\n",
              "      <td>Room Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>62</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>Men</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2021-01-01</td>\n",
              "      <td>62</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>Men</td>\n",
              "      <td>Transitional</td>\n",
              "      <td>Bed Based Capacity</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee4e30dc-4dd0-4842-b6db-d840d8f6b084')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee4e30dc-4dd0-4842-b6db-d840d8f6b084 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee4e30dc-4dd0-4842-b6db-d840d8f6b084');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4636b80-be05-425a-94de-27b6c183de29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4636b80-be05-425a-94de-27b6c183de29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4636b80-be05-425a-94de-27b6c183de29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"LOCATION_CITY\"]==\"Toronto\"].groupby([\"OCCUPANCY_DATE\", \"LOCATION_ID\", \"SHELTER_ID\", \"SECTOR\", \"PROGRAM_MODEL\", \"CAPACITY_TYPE\"]).count()[\"_id\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1NKMnEaNJd9",
        "outputId": "03f58d75-a134-4880-ed90-aaec826a3ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    96554\n",
              "2     3690\n",
              "4      767\n",
              "3       56\n",
              "5       43\n",
              "Name: _id, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df[\"LOCATION_CITY\"]==\"Toronto\"].groupby([\"OCCUPANCY_DATE\"]).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "Wf8-22cRNzWr",
        "outputId": "ea9cd798-bcfc-4b98-a713-cf016839ba53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                _id  ORGANIZATION_ID  ORGANIZATION_NAME  SHELTER_ID  \\\n",
              "OCCUPANCY_DATE                                                        \n",
              "2021-01-01      109              109                109         109   \n",
              "2021-01-02      109              109                109         109   \n",
              "2021-01-03      109              109                109         109   \n",
              "2021-01-04      109              109                109         109   \n",
              "2021-01-05      109              109                109         109   \n",
              "...             ...              ...                ...         ...   \n",
              "2023-10-07       97               97                 97          97   \n",
              "2023-10-08       97               97                 97          97   \n",
              "2023-10-09       97               97                 97          97   \n",
              "2023-10-10       97               97                 97          97   \n",
              "2023-10-11       98               98                 98          98   \n",
              "\n",
              "                SHELTER_GROUP  LOCATION_ID  LOCATION_NAME  LOCATION_ADDRESS  \\\n",
              "OCCUPANCY_DATE                                                                \n",
              "2021-01-01                109          109            109               109   \n",
              "2021-01-02                109          109            109               109   \n",
              "2021-01-03                109          109            109               109   \n",
              "2021-01-04                109          109            109               109   \n",
              "2021-01-05                109          109            109               109   \n",
              "...                       ...          ...            ...               ...   \n",
              "2023-10-07                 97           97             97                97   \n",
              "2023-10-08                 97           97             97                97   \n",
              "2023-10-09                 97           97             97                97   \n",
              "2023-10-10                 97           97             97                97   \n",
              "2023-10-11                 98           98             98                98   \n",
              "\n",
              "                LOCATION_POSTAL_CODE  LOCATION_CITY  ...  V109  V110  V111  \\\n",
              "OCCUPANCY_DATE                                       ...                     \n",
              "2021-01-01                       109            109  ...   106   106   106   \n",
              "2021-01-02                       109            109  ...   106   106   106   \n",
              "2021-01-03                       109            109  ...   106   106   106   \n",
              "2021-01-04                       109            109  ...   106   106   106   \n",
              "2021-01-05                       109            109  ...   106   106   106   \n",
              "...                              ...            ...  ...   ...   ...   ...   \n",
              "2023-10-07                        97             97  ...    94    94    94   \n",
              "2023-10-08                        97             97  ...    94    94    94   \n",
              "2023-10-09                        97             97  ...    94    94    94   \n",
              "2023-10-10                        97             97  ...    94    94    94   \n",
              "2023-10-11                        98             98  ...    95    95    95   \n",
              "\n",
              "                V112  V113  V114  V115  V116  V117  V118  \n",
              "OCCUPANCY_DATE                                            \n",
              "2021-01-01       106   106   106   106   106   106   106  \n",
              "2021-01-02       106   106   106   106   106   106   106  \n",
              "2021-01-03       106   106   106   106   106   106   106  \n",
              "2021-01-04       106   106   106   106   106   106   106  \n",
              "2021-01-05       106   106   106   106   106   106   106  \n",
              "...              ...   ...   ...   ...   ...   ...   ...  \n",
              "2023-10-07        94    94    94    94    94    94    94  \n",
              "2023-10-08        94    94    94    94    94    94    94  \n",
              "2023-10-09        94    94    94    94    94    94    94  \n",
              "2023-10-10        94    94    94    94    94    94    94  \n",
              "2023-10-11        95    95    95    95    95    95    95  \n",
              "\n",
              "[1014 rows x 154 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9784392e-36cc-4cd0-af24-d87771c8f6e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>ORGANIZATION_ID</th>\n",
              "      <th>ORGANIZATION_NAME</th>\n",
              "      <th>SHELTER_ID</th>\n",
              "      <th>SHELTER_GROUP</th>\n",
              "      <th>LOCATION_ID</th>\n",
              "      <th>LOCATION_NAME</th>\n",
              "      <th>LOCATION_ADDRESS</th>\n",
              "      <th>LOCATION_POSTAL_CODE</th>\n",
              "      <th>LOCATION_CITY</th>\n",
              "      <th>...</th>\n",
              "      <th>V109</th>\n",
              "      <th>V110</th>\n",
              "      <th>V111</th>\n",
              "      <th>V112</th>\n",
              "      <th>V113</th>\n",
              "      <th>V114</th>\n",
              "      <th>V115</th>\n",
              "      <th>V116</th>\n",
              "      <th>V117</th>\n",
              "      <th>V118</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCUPANCY_DATE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-01-01</th>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-02</th>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-03</th>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-04</th>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-01-05</th>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>109</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-07</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-08</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-09</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-10</th>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>97</td>\n",
              "      <td>...</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-10-11</th>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>98</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1014 rows × 154 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9784392e-36cc-4cd0-af24-d87771c8f6e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9784392e-36cc-4cd0-af24-d87771c8f6e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9784392e-36cc-4cd0-af24-d87771c8f6e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-87e0f9c3-5ae3-4d9c-a434-c125919e0079\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87e0f9c3-5ae3-4d9c-a434-c125919e0079')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-87e0f9c3-5ae3-4d9c-a434-c125919e0079 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_location_metadata_data(data_path, include_capacity=True, include_shelter_id=False):\n",
        "    all_shelter_data = pd.read_csv(data_path, low_memory=False)\n",
        "    all_shelter_data['OCCUPANCY_DATE'] = pd.to_datetime(all_shelter_data['OCCUPANCY_DATE'])\n",
        "    toronto_data = all_shelter_data[all_shelter_data[\"LOCATION_CITY\"] == \"Toronto\"]\n",
        "    toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
        "    toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
        "    toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n",
        "    drop_cols = ['_id', 'ORGANIZATION_ID', 'ORGANIZATION_NAME', 'LOCATION_ID', 'SHELTER_GROUP',\n",
        "                 'LOCATION_NAME', 'LOCATION_ADDRESS', 'LOCATION_CITY', 'LOCATION_PROVINCE', 'PROGRAM_ID',\n",
        "                 'PROGRAM_NAME', 'OVERNIGHT_SERVICE_TYPE', 'PROGRAM_AREA', 'CAPACITY_FUNDING_BED',\n",
        "                 'OCCUPIED_BEDS', 'UNOCCUPIED_BEDS', 'CAPACITY_FUNDING_ROOM', 'OCCUPIED_ROOMS', 'UNOCCUPIED_ROOMS',\n",
        "                 'OCCUPANCY_RATE_ROOMS', \"OCCUPANCY_RATE_BEDS\", 'UNAVAILABLE_BEDS','UNAVAILABLE_ROOMS'\n",
        "                 ]\n",
        "    if not include_capacity:\n",
        "        drop_cols.extend(['CAPACITY_ACTUAL_BED', 'CAPACITY_ACTUAL_ROOM'])\n",
        "    if not include_shelter_id:\n",
        "        drop_cols.append('SHELTER_ID')\n",
        "    toronto_data_dr = toronto_data.drop(columns=drop_cols)\n",
        "    toronto_data_dr_nan = toronto_data_dr[toronto_data_dr[\"PROGRAM_MODEL\"].notna()]\n",
        "    # Creating list of dummy columns\n",
        "    to_get_dummies_for = ['SECTOR']\n",
        "    # Creating dummy variables\n",
        "    toronto_data_dr_nan = pd.get_dummies(data=toronto_data_dr_nan, columns=to_get_dummies_for)\n",
        "\n",
        "    # Mapping overtime and attrition\n",
        "    dict_prog_mod = {'Emergency': 1, 'Transitional': 0}\n",
        "    dict_cap_type = {'Bed Based Capacity': 1, 'Room Based Capacity': 0}\n",
        "\n",
        "    # toronto_data_dr_nan['prog_mod'] = toronto_data_dr_nan[\"PROGRAM_MODEL\"].map(dict_prog_mod)\n",
        "    toronto_data_dr_nan['cap_type'] = toronto_data_dr_nan[\"CAPACITY_TYPE\"].map(dict_cap_type)\n",
        "    toronto_data_dr_nan = toronto_data_dr_nan.drop(columns=[\"PROGRAM_MODEL\", \"CAPACITY_TYPE\"])\n",
        "    # toronto_data_dr_nan[\"postal_code\"] = toronto_data_dr_nan['LOCATION_POSTAL_CODE'].apply(lambda x: x.split(\" \")[0])\n",
        "    # toronto_data_dr_nan[\"postal_code\"] = toronto_data_dr_nan[\"postal_code\"].astype('category')\n",
        "    # toronto_data_dr_nan[\"postal_code_num\"] = pd.Categorical(toronto_data_dr_nan[\"postal_code\"]).codes\n",
        "    final_df = toronto_data_dr_nan.drop(columns=[\"LOCATION_POSTAL_CODE\", 'OCCUPANCY_DATE', 'Neighbourhood'])\n",
        "    occu_final_df = toronto_data_dr_nan.drop(columns=[\"LOCATION_POSTAL_CODE\", 'Neighbourhood'])\n",
        "    occu_final_df = occu_final_df[occu_final_df['YEAR']==2023]\n",
        "    info = {\"test_dated\": occu_final_df}\n",
        "    final_df = final_df.fillna(value=0.0)\n",
        "    test = final_df[final_df['YEAR']==2023]\n",
        "    train = final_df[(final_df['YEAR']==2021) | (final_df['YEAR']==2022)]\n",
        "    train = train.drop(columns=['YEAR'])\n",
        "    test = test.drop(columns=['YEAR'])\n",
        "    X_train, X_test, y_train, y_test = train.drop(columns=['SERVICE_USER_COUNT']), test.drop(columns=['SERVICE_USER_COUNT']), train['SERVICE_USER_COUNT'], test['SERVICE_USER_COUNT']\n",
        "    sc = StandardScaler()\n",
        "    # print(list(X_train.select_dtypes(include=['object']).columns))\n",
        "    # Fit_transform on train data\n",
        "    X_train_scaled = sc.fit_transform(X_train)\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "\n",
        "    # Transform on test data\n",
        "    X_test_scaled = sc.transform(X_test)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_train.columns)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, info"
      ],
      "metadata": {
        "id": "FUX36HqlKn9y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eecY3KOPMfvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# from pytorch_transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "from transformers import AutoTokenizer, BertModel, OpenAIGPTModel\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening under the hood, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "\n",
        "def encode_text(text, max_len=50):\n",
        "    \"\"\"\n",
        "    Given a list of text, tokenize it and encode it\n",
        "    :param max_len: Max length of string\n",
        "    :param text: list[str]\n",
        "    :return: tensor of hidden state encodings (N x M x 768) and the attention masks (N x M)\n",
        "            where M is the length of the largest string.\n",
        "    \"\"\"\n",
        "    text.append('A '*max_len)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"openai-gpt\")\n",
        "    tokenizer.pad_token = '[PAD]'\n",
        "    tokenizer.padding_side = \"left\"\n",
        "    # Tokenize input\n",
        "    tokenized_text = tokenizer(text, return_tensors='pt', padding=True)\n",
        "    # Load pre-trained model (weights)\n",
        "    model = OpenAIGPTModel.from_pretrained(\"openai-gpt\")\n",
        "    outputs = model(input_ids=tokenized_text['input_ids'],\n",
        "                    attention_mask=tokenized_text['attention_mask'],\n",
        "                    # pad_token_id=tokenizer.pad_token_id,\n",
        "                    )\n",
        "    last_hidden_states = outputs.last_hidden_state\n",
        "    return last_hidden_states[:-1], tokenized_text['attention_mask'][:-1]\n"
      ],
      "metadata": {
        "id": "qgx6fmsbFAjE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            # (BS, F)\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(32, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, output_dim),\n",
        "            # (BS, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TimeModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, seq_len):\n",
        "        super(TimeModel, self).__init__()\n",
        "\n",
        "        # self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.fc0 = nn.Linear(input_dim, 256)\n",
        "        self.fc1 = nn.Linear(256, hidden_dim)\n",
        "        self.positional_encoding = PositionalEncoding(hidden_dim, max_len=1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads, batch_first=True, dropout=0.3)\n",
        "        encoder_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers, encoder_norm)\n",
        "        self.fc_dec = nn.Linear(hidden_dim, 256)\n",
        "        self.fc_dec2 = nn.Linear(256, 32)\n",
        "        self.fc = nn.Linear(32*seq_len, 32)\n",
        "        self.fc2 = nn.Linear(32, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.embedding(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        # (BS, SEQ, F)\n",
        "        x = self.fc0(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = self.positional_encoding(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = self.encoder(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = nn.Dropout(0.5)(x)\n",
        "        x = self.fc_dec(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = nn.Dropout(0.5)(x)\n",
        "        x = self.fc_dec2(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = nn.Dropout(0.5)(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = self.fc2(x)\n",
        "        # (BS, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('x:', x.shape)\n",
        "        # print('self.pe:', self.pe.shape)\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x\n",
        "\n",
        "\n",
        "class NewsModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, seq_len):\n",
        "        super(NewsModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.fc0 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.positional_encoding = PositionalEncoding(hidden_dim, max_len=1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads, batch_first=True, dropout=0.1)\n",
        "        encoder_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers, encoder_norm)\n",
        "        self.fc = nn.Linear(hidden_dim*seq_len, 32)\n",
        "        self.fc2 = nn.Linear(32, output_dim)\n",
        "\n",
        "    def forward(self, x, news):\n",
        "        # x = self.embedding(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        # (BS, SEQ, NF)\n",
        "        news_embed = encode_text(news)\n",
        "        x = self.fc0(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = self.positional_encoding(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        # (BS, SEQ, F)\n",
        "        x = self.encoder(x)\n",
        "        #\n",
        "        x = torch.concat([x, news_embed], dim=1)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.nn.ReLU(x)\n",
        "        x = self.fc2(x)\n",
        "        # (BS, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "g05Pk-C3E6wE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mg6FaUk0u5lZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "# from model import *\n",
        "# from data import *\n",
        "from torchsummary import summary\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "\n",
        "def train(model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_file_name,\n",
        "          max_epochs_stop=3,\n",
        "          n_epochs=20,\n",
        "          print_every=2):\n",
        "    \"\"\"Train a PyTorch Model\n",
        "\n",
        "    Params\n",
        "    --------\n",
        "        model (PyTorch model): cnn to train\n",
        "        criterion (PyTorch loss): objective to minimize\n",
        "        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n",
        "        train_loader (PyTorch dataloader): training dataloader to iterate through\n",
        "        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n",
        "        save_file_name (str ending in '.pt'): file path to save the model state dict\n",
        "        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n",
        "        n_epochs (int): maximum number of training epochs\n",
        "        print_every (int): frequency of epochs to print training stats\n",
        "\n",
        "    Returns\n",
        "    --------\n",
        "        model (PyTorch model): trained cnn with best weights\n",
        "        history (DataFrame): history of train and validation loss\n",
        "    \"\"\"\n",
        "\n",
        "    # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    history = []\n",
        "\n",
        "    # Number of epochs already trained (if using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'Starting Training from Scratch.\\n')\n",
        "\n",
        "    overall_start = timer()\n",
        "\n",
        "    # Main loop\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        # keep track of training and validation loss each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        # Set to training\n",
        "        model.train()\n",
        "        start = timer()\n",
        "\n",
        "        # Training loop\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            # Tensors to gpu\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predicted outputs are log probabilities\n",
        "            output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Track training progress\n",
        "            print(\n",
        "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "        # After training loops ends, start validation\n",
        "        else:\n",
        "            model.epochs += 1\n",
        "\n",
        "            # Don't need to keep track of gradients\n",
        "            with torch.no_grad():\n",
        "                # Set to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Validation loop\n",
        "                for data, target in valid_loader:\n",
        "                    # Tensors to gpu\n",
        "                    if train_on_gpu:\n",
        "                        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "                    # Forward pass\n",
        "                    output = model(data)\n",
        "\n",
        "                    # Validation loss\n",
        "                    loss = criterion(output, target)\n",
        "                    # Multiply average loss times the number of examples in batch\n",
        "                    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                # Calculate average losses\n",
        "                train_loss = train_loss / len(train_loader.dataset)\n",
        "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "                history.append([train_loss, valid_loss])\n",
        "\n",
        "                # Print training and validation results\n",
        "                if (epoch + 1) % print_every == 0:\n",
        "                    print(\n",
        "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
        "                    )\n",
        "                # Save the model if validation loss decreases\n",
        "                if valid_loss < valid_loss_min:\n",
        "                    # Save model\n",
        "                    torch.save(model.state_dict(), save_file_name)\n",
        "                    # Track improvement\n",
        "                    epochs_no_improve = 0\n",
        "                    valid_loss_min = valid_loss\n",
        "                    best_epoch = epoch\n",
        "\n",
        "                # Otherwise increment count of epochs with no improvement\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    # Trigger early stopping\n",
        "                    if epochs_no_improve >= max_epochs_stop:\n",
        "                        print(\n",
        "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.4f}'\n",
        "                        )\n",
        "                        total_time = timer() - overall_start\n",
        "                        print(\n",
        "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
        "                        )\n",
        "\n",
        "                        # Load the best state dict\n",
        "                        model.load_state_dict(torch.load(save_file_name))\n",
        "                        # Attach the optimizer\n",
        "                        model.optimizer = optimizer\n",
        "\n",
        "                        # Format history\n",
        "                        history = pd.DataFrame(\n",
        "                            history,\n",
        "                            columns=['train_loss', 'valid_loss'])\n",
        "                        return model, history\n",
        "\n",
        "    # Attach the optimizer\n",
        "    model.optimizer = optimizer\n",
        "    # Record overall time and print out stats\n",
        "    total_time = timer() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.4f}'\n",
        "    )\n",
        "    print(\n",
        "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    # Format history\n",
        "    history = pd.DataFrame(\n",
        "        history,\n",
        "        columns=['train_loss', 'valid_loss'])\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def plot_loss(history, filename):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for c in ['train_loss', 'valid_loss']:\n",
        "        plt.plot(\n",
        "            history[c], label=c)\n",
        "    plt.legend()\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Average cross entropy')\n",
        "    plt.title('Training, Validation and testing Losses')\n",
        "    plt.savefig(filename)\n",
        "\n",
        "\n",
        "def train_mlp():\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, _ = load_data(include_capacity=True)\n",
        "    train_dataset = DefaultDataset(X_train_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_train)+1.0e-1, axis=-1)))\n",
        "    test_dataset = DefaultDataset(X_test_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_test)+1.0e-1, axis=-1)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[0]\n",
        "    model = MLP(input_shape, 1)\n",
        "    summary(model, input_size=(input_shape,), batch_size=128)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=3.0e-5)\n",
        "    model, history = train(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        train_dataloader,\n",
        "        test_dataloader,\n",
        "        save_file_name='./mlp_model_log_cap.pt',\n",
        "        max_epochs_stop=20,\n",
        "        n_epochs=100,\n",
        "        print_every=1)\n",
        "\n",
        "    plot_loss(history, \"./loss.jpg\")\n",
        "\n",
        "\n",
        "def train_seq():\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test = load_data()\n",
        "    train_dataset = SequenceDataset(X_train_scaled.to_numpy(), np.log10(np.expand_dims(np.asarray(y_train), axis=-1)))\n",
        "    test_dataset = SequenceDataset(X_test_scaled.to_numpy(), np.log10(np.expand_dims(np.asarray(y_test), axis=-1)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[0]\n",
        "    model = TimeModel(input_shape,\n",
        "                      hidden_dim=256,\n",
        "                      num_layers=1,\n",
        "                      num_heads=4,\n",
        "                      output_dim=1,\n",
        "                      seq_len=30)\n",
        "    summary(model, input_size=(14, 30), batch_size=128)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=512, shuffle=False)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
        "    model, history = train(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        train_dataloader,\n",
        "        test_dataloader,\n",
        "        save_file_name='./trans_model_log.pt',\n",
        "        max_epochs_stop=5,\n",
        "        n_epochs=10,\n",
        "        print_every=1)\n",
        "\n",
        "    plot_loss(history, \"./loss.jpg\")\n",
        "\n",
        "\n",
        "def evaluate(model_path):\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, df_copy = load_data(include_capacity=True)\n",
        "    train_dataset = DefaultDataset(X_train_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_train), axis=-1)))\n",
        "    test_dataset = DefaultDataset(X_test_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_test), axis=-1)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[0]\n",
        "    model = MLP(input_shape, 1)\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    y_pred = model(torch.from_numpy(X_test_scaled.to_numpy()).float())\n",
        "    y_pred = y_pred.detach().numpy()\n",
        "    y_pred = np.squeeze(np.exp(y_pred))\n",
        "    df_copy['PRED_SC'] = y_pred\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(df_copy.groupby('OCCUPANCY_DATE')['SERVICE_USER_COUNT'].mean())\n",
        "    plt.plot(df_copy.groupby('OCCUPANCY_DATE')['PRED_SC'].mean())\n",
        "    plt.legend(['Actual', 'Predicted'])\n",
        "    plt.xlabel('Day')\n",
        "    plt.ylabel('Average user count')\n",
        "    plt.title('Evaluation of predicted user counts')\n",
        "    plt.savefig('./trained_models/mlp_model_log_cap_eval.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP"
      ],
      "metadata": {
        "id": "Y8MlOCzy2we_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mlp():\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, _ = load_location_metadata_data(combined_data_path, include_capacity=True, include_shelter_id=True)\n",
        "    train_dataset = DefaultDataset(X_train_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_train)+1.0e-1, axis=-1)))\n",
        "    test_dataset = DefaultDataset(X_test_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_test)+1.0e-1, axis=-1)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[0]\n",
        "    model = MLP(input_shape, 1)\n",
        "    print(f\"Input features {input_shape}\")\n",
        "    summary(model, input_size=(input_shape,), batch_size=128)\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=512, shuffle=True)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-5, weight_decay=0.1)\n",
        "    model, history = train(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        train_dataloader,\n",
        "        test_dataloader,\n",
        "        save_file_name='./mlp_model_log_loc_feat_shelid_cap.pt',\n",
        "        max_epochs_stop=20,\n",
        "        n_epochs=100,\n",
        "        print_every=1)\n",
        "\n",
        "    plot_loss(history, \"./loss.jpg\")\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "Hp74YK3rElbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = train_mlp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NxSs00kMNHES",
        "outputId": "ee2ad970-49cd-436b-c578-c3f7c883a9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-84-bdd0dc5895d8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-84-bdd0dc5895d8>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-84-bdd0dc5895d8>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input features 135\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [128, 128]          17,408\n",
            "              ReLU-2                 [128, 128]               0\n",
            "           Dropout-3                 [128, 128]               0\n",
            "            Linear-4                 [128, 256]          33,024\n",
            "              ReLU-5                 [128, 256]               0\n",
            "           Dropout-6                 [128, 256]               0\n",
            "            Linear-7                  [128, 64]          16,448\n",
            "              ReLU-8                  [128, 64]               0\n",
            "           Dropout-9                  [128, 64]               0\n",
            "           Linear-10                  [128, 32]           2,080\n",
            "             ReLU-11                  [128, 32]               0\n",
            "          Dropout-12                  [128, 32]               0\n",
            "           Linear-13                  [128, 16]             528\n",
            "             ReLU-14                  [128, 16]               0\n",
            "          Dropout-15                  [128, 16]               0\n",
            "           Linear-16                  [128, 16]             272\n",
            "             ReLU-17                  [128, 16]               0\n",
            "          Dropout-18                  [128, 16]               0\n",
            "           Linear-19                  [128, 16]             272\n",
            "             ReLU-20                  [128, 16]               0\n",
            "           Linear-21                   [128, 1]              17\n",
            "================================================================\n",
            "Total params: 70,049\n",
            "Trainable params: 70,049\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.07\n",
            "Forward/backward pass size (MB): 1.53\n",
            "Params size (MB): 0.27\n",
            "Estimated Total Size (MB): 1.87\n",
            "----------------------------------------------------------------\n",
            "Starting Training from Scratch.\n",
            "\n",
            "\n",
            "Epoch: 0 \tTraining Loss: 12.7966 \tValidation Loss: 10.4728\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 5.8907 \tValidation Loss: 3.2537\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 4.6737 \tValidation Loss: 2.8476\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 3.8995 \tValidation Loss: 2.3172\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 3.3455 \tValidation Loss: 1.9882\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 2.8684 \tValidation Loss: 1.6764\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 2.4402 \tValidation Loss: 1.4403\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 2.1156 \tValidation Loss: 1.1449\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 1.8206 \tValidation Loss: 0.9897\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 1.5906 \tValidation Loss: 0.8769\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 1.3999 \tValidation Loss: 0.7590\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 1.2516 \tValidation Loss: 0.6482\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 1.1475 \tValidation Loss: 0.5878\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 1.0606 \tValidation Loss: 0.5940\n",
            "\n",
            "Epoch: 14 \tTraining Loss: 0.9959 \tValidation Loss: 0.5408\n",
            "\n",
            "Epoch: 15 \tTraining Loss: 0.9301 \tValidation Loss: 0.5383\n",
            "\n",
            "Epoch: 16 \tTraining Loss: 0.8871 \tValidation Loss: 0.4912\n",
            "\n",
            "Epoch: 17 \tTraining Loss: 0.8532 \tValidation Loss: 0.5019\n",
            "\n",
            "Epoch: 18 \tTraining Loss: 0.8049 \tValidation Loss: 0.4895\n",
            "\n",
            "Epoch: 19 \tTraining Loss: 0.7776 \tValidation Loss: 0.4552\n",
            "\n",
            "Epoch: 20 \tTraining Loss: 0.7451 \tValidation Loss: 0.4568\n",
            "\n",
            "Epoch: 21 \tTraining Loss: 0.7271 \tValidation Loss: 0.4396\n",
            "\n",
            "Epoch: 22 \tTraining Loss: 0.7042 \tValidation Loss: 0.4352\n",
            "\n",
            "Epoch: 23 \tTraining Loss: 0.6934 \tValidation Loss: 0.4087\n",
            "\n",
            "Epoch: 24 \tTraining Loss: 0.6722 \tValidation Loss: 0.4234\n",
            "\n",
            "Epoch: 25 \tTraining Loss: 0.6523 \tValidation Loss: 0.4193\n",
            "\n",
            "Epoch: 26 \tTraining Loss: 0.6366 \tValidation Loss: 0.4184\n",
            "\n",
            "Epoch: 27 \tTraining Loss: 0.6281 \tValidation Loss: 0.4161\n",
            "\n",
            "Epoch: 28 \tTraining Loss: 0.6199 \tValidation Loss: 0.4005\n",
            "\n",
            "Epoch: 29 \tTraining Loss: 0.6083 \tValidation Loss: 0.4137\n",
            "\n",
            "Epoch: 30 \tTraining Loss: 0.6008 \tValidation Loss: 0.4164\n",
            "\n",
            "Epoch: 31 \tTraining Loss: 0.5954 \tValidation Loss: 0.3987\n",
            "\n",
            "Epoch: 32 \tTraining Loss: 0.5865 \tValidation Loss: 0.3934\n",
            "\n",
            "Epoch: 33 \tTraining Loss: 0.5789 \tValidation Loss: 0.3956\n",
            "\n",
            "Epoch: 34 \tTraining Loss: 0.5774 \tValidation Loss: 0.3917\n",
            "\n",
            "Epoch: 35 \tTraining Loss: 0.5735 \tValidation Loss: 0.4033\n",
            "\n",
            "Epoch: 36 \tTraining Loss: 0.5664 \tValidation Loss: 0.3829\n",
            "\n",
            "Epoch: 37 \tTraining Loss: 0.5632 \tValidation Loss: 0.3992\n",
            "\n",
            "Epoch: 38 \tTraining Loss: 0.5620 \tValidation Loss: 0.3909\n",
            "\n",
            "Epoch: 39 \tTraining Loss: 0.5591 \tValidation Loss: 0.3810\n",
            "\n",
            "Epoch: 40 \tTraining Loss: 0.5526 \tValidation Loss: 0.3941\n",
            "\n",
            "Epoch: 41 \tTraining Loss: 0.5481 \tValidation Loss: 0.3853\n",
            "\n",
            "Epoch: 42 \tTraining Loss: 0.5471 \tValidation Loss: 0.3728\n",
            "\n",
            "Epoch: 43 \tTraining Loss: 0.5426 \tValidation Loss: 0.3777\n",
            "\n",
            "Epoch: 44 \tTraining Loss: 0.5402 \tValidation Loss: 0.3711\n",
            "\n",
            "Epoch: 45 \tTraining Loss: 0.5358 \tValidation Loss: 0.3673\n",
            "\n",
            "Epoch: 46 \tTraining Loss: 0.5375 \tValidation Loss: 0.3877\n",
            "\n",
            "Epoch: 47 \tTraining Loss: 0.5362 \tValidation Loss: 0.3721\n",
            "\n",
            "Epoch: 48 \tTraining Loss: 0.5304 \tValidation Loss: 0.3688\n",
            "\n",
            "Epoch: 49 \tTraining Loss: 0.5346 \tValidation Loss: 0.3957\n",
            "\n",
            "Epoch: 50 \tTraining Loss: 0.5285 \tValidation Loss: 0.3572\n",
            "\n",
            "Epoch: 51 \tTraining Loss: 0.5280 \tValidation Loss: 0.3735\n",
            "\n",
            "Epoch: 52 \tTraining Loss: 0.5265 \tValidation Loss: 0.3712\n",
            "\n",
            "Epoch: 53 \tTraining Loss: 0.5268 \tValidation Loss: 0.3698\n",
            "\n",
            "Epoch: 54 \tTraining Loss: 0.5216 \tValidation Loss: 0.3642\n",
            "\n",
            "Epoch: 55 \tTraining Loss: 0.5223 \tValidation Loss: 0.3518\n",
            "\n",
            "Epoch: 56 \tTraining Loss: 0.5165 \tValidation Loss: 0.3489\n",
            "\n",
            "Epoch: 57 \tTraining Loss: 0.5164 \tValidation Loss: 0.3673\n",
            "\n",
            "Epoch: 58 \tTraining Loss: 0.5179 \tValidation Loss: 0.3686\n",
            "\n",
            "Epoch: 59 \tTraining Loss: 0.5169 \tValidation Loss: 0.3757\n",
            "\n",
            "Epoch: 60 \tTraining Loss: 0.5140 \tValidation Loss: 0.3538\n",
            "\n",
            "Epoch: 61 \tTraining Loss: 0.5152 \tValidation Loss: 0.3596\n",
            "\n",
            "Epoch: 62 \tTraining Loss: 0.5090 \tValidation Loss: 0.3484\n",
            "\n",
            "Epoch: 63 \tTraining Loss: 0.5132 \tValidation Loss: 0.3510\n",
            "\n",
            "Epoch: 64 \tTraining Loss: 0.5108 \tValidation Loss: 0.3582\n",
            "\n",
            "Epoch: 65 \tTraining Loss: 0.5079 \tValidation Loss: 0.3733\n",
            "\n",
            "Epoch: 66 \tTraining Loss: 0.5080 \tValidation Loss: 0.3625\n",
            "\n",
            "Epoch: 67 \tTraining Loss: 0.5054 \tValidation Loss: 0.3573\n",
            "\n",
            "Epoch: 68 \tTraining Loss: 0.5064 \tValidation Loss: 0.3472\n",
            "\n",
            "Epoch: 69 \tTraining Loss: 0.5051 \tValidation Loss: 0.3466\n",
            "\n",
            "Epoch: 70 \tTraining Loss: 0.5029 \tValidation Loss: 0.3609\n",
            "\n",
            "Epoch: 71 \tTraining Loss: 0.5017 \tValidation Loss: 0.3531\n",
            "\n",
            "Epoch: 72 \tTraining Loss: 0.5022 \tValidation Loss: 0.3793\n",
            "\n",
            "Epoch: 73 \tTraining Loss: 0.5029 \tValidation Loss: 0.3385\n",
            "\n",
            "Epoch: 74 \tTraining Loss: 0.4977 \tValidation Loss: 0.3667\n",
            "\n",
            "Epoch: 75 \tTraining Loss: 0.5042 \tValidation Loss: 0.3595\n",
            "\n",
            "Epoch: 76 \tTraining Loss: 0.5006 \tValidation Loss: 0.3526\n",
            "\n",
            "Epoch: 77 \tTraining Loss: 0.5003 \tValidation Loss: 0.3516\n",
            "\n",
            "Epoch: 78 \tTraining Loss: 0.5008 \tValidation Loss: 0.3470\n",
            "\n",
            "Epoch: 79 \tTraining Loss: 0.5010 \tValidation Loss: 0.3477\n",
            "\n",
            "Epoch: 80 \tTraining Loss: 0.4981 \tValidation Loss: 0.3500\n",
            "\n",
            "Epoch: 81 \tTraining Loss: 0.4979 \tValidation Loss: 0.3587\n",
            "\n",
            "Epoch: 82 \tTraining Loss: 0.4962 \tValidation Loss: 0.3516\n",
            "\n",
            "Epoch: 83 \tTraining Loss: 0.4966 \tValidation Loss: 0.3503\n",
            "\n",
            "Epoch: 84 \tTraining Loss: 0.4974 \tValidation Loss: 0.3441\n",
            "\n",
            "Epoch: 85 \tTraining Loss: 0.4971 \tValidation Loss: 0.3416\n",
            "\n",
            "Epoch: 86 \tTraining Loss: 0.4993 \tValidation Loss: 0.3552\n",
            "\n",
            "Epoch: 87 \tTraining Loss: 0.4960 \tValidation Loss: 0.3434\n",
            "\n",
            "Epoch: 88 \tTraining Loss: 0.4958 \tValidation Loss: 0.3415\n",
            "\n",
            "Epoch: 89 \tTraining Loss: 0.4949 \tValidation Loss: 0.3450\n",
            "\n",
            "Epoch: 90 \tTraining Loss: 0.4939 \tValidation Loss: 0.3581\n",
            "\n",
            "Epoch: 91 \tTraining Loss: 0.4971 \tValidation Loss: 0.3475\n",
            "\n",
            "Epoch: 92 \tTraining Loss: 0.4927 \tValidation Loss: 0.3499\n",
            "\n",
            "Epoch: 93 \tTraining Loss: 0.4940 \tValidation Loss: 0.3404\n",
            "\n",
            "Early Stopping! Total epochs: 93. Best epoch: 73 with loss: 0.3385\n",
            "842.99 total seconds elapsed. 8.97 seconds per epoch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model_path):\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, df_copy = load_location_metadata_data(combined_data_path, include_capacity=True, include_shelter_id=True)\n",
        "    train_dataset = DefaultDataset(X_train_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_train), axis=-1)))\n",
        "    test_dataset = DefaultDataset(X_test_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_test), axis=-1)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[0]\n",
        "    model = MLP(input_shape, 1)\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    y_pred = model(torch.from_numpy(X_test_scaled.to_numpy()).float())\n",
        "    y_pred = y_pred.detach().numpy()\n",
        "    y_pred = np.squeeze(np.exp(y_pred))\n",
        "    df_copy['PRED_SC'] = y_pred\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(df_copy.groupby('OCCUPANCY_DATE')['SERVICE_USER_COUNT'].sum())\n",
        "    plt.plot(df_copy.groupby('OCCUPANCY_DATE')['PRED_SC'].sum())\n",
        "    plt.legend(['Actual', 'Predicted'])\n",
        "    plt.xlabel('Day')\n",
        "    plt.ylabel('Average user count')\n",
        "    plt.title('Evaluation of predicted user counts')\n",
        "    plt.savefig('./mlp_model_log_loc_feat_shelid_cap_eval.jpg')"
      ],
      "metadata": {
        "id": "usZrxDvGkgFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate('/content/mlp_model_log_loc_feat_shelid_cap.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "fys2m0rikzXa",
        "outputId": "0b9f7fb8-73b8-4d66-fa02-0052bdbf8951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-84-bdd0dc5895d8>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-84-bdd0dc5895d8>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-84-bdd0dc5895d8>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer"
      ],
      "metadata": {
        "id": "pYTz0D1G2z8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads, output_dim, seq_len):\n",
        "        super(TimeModel, self).__init__()\n",
        "\n",
        "        # self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.fc0 = nn.Linear(input_dim, 256)\n",
        "        self.fc1 = nn.Linear(256, hidden_dim)\n",
        "        self.positional_encoding = PositionalEncoding(hidden_dim, max_len=1)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_heads, batch_first=True, dropout=0.3)\n",
        "        encoder_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers, encoder_norm)\n",
        "        self.fc_dec = nn.Linear(hidden_dim, 256)\n",
        "        self.fc_dec2 = nn.Linear(256, 32)\n",
        "        self.fc = nn.Linear(32*seq_len, 32)\n",
        "        self.fc2 = nn.Linear(32, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.embedding(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = self.fc0(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = self.fc1(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = self.positional_encoding(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = self.encoder(x)\n",
        "        # print('x:', x[:2, :, :])\n",
        "        # print('x:', x[:2, :, :])\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = nn.Dropout(0.5)(x)\n",
        "        x = self.fc_dec(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = nn.Dropout(0.5)(x)\n",
        "        x = self.fc_dec2(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = nn.Dropout(0.5)(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('x:', x.shape)\n",
        "        # print('self.pe:', self.pe.shape)\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x"
      ],
      "metadata": {
        "id": "WTA_TemO9zHu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, data_x, data_y, window=30):\n",
        "        # self.x = torch.from_numpy(data_x)\n",
        "        # self.y = torch.from_numpy(data_y)\n",
        "        cols = [col for col in data_x.columns if col[0]!='V']\n",
        "        data_cols = [col for col in data_x.columns]\n",
        "        data_cols.remove(\"OCCUPANCY_DATE\")\n",
        "        self.data_cols = data_cols\n",
        "        cols.remove(\"OCCUPANCY_DATE\")\n",
        "        cols.remove(\"SERVICE_USER_COUNT\")\n",
        "        cols.remove(\"MONTH\")\n",
        "        cols.remove(\"DAY\")\n",
        "        data_x[\"GNUM\"] = data_x.groupby(cols).ngroup()\n",
        "        data_x[\"LOG_CNT\"] = data_y\n",
        "        self.x = data_x\n",
        "        self.cumsum = np.cumsum(np.clip((data_x.groupby(\"GNUM\").count()[\"OCCUPANCY_DATE\"].to_numpy() - window), a_min=0, a_max=None))\n",
        "        self.length = self.cumsum[-1]\n",
        "        self.window = window\n",
        "        self.gnum_subsets = []\n",
        "        for gnum in self.x[\"GNUM\"]:\n",
        "            subset = self.x[self.x[\"GNUM\"]==gnum]\n",
        "            self.gnum_subsets.append((subset[self.data_cols], np.expand_dims(subset[\"LOG_CNT\"].to_numpy(), axis=-1)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        diff = self.cumsum-index\n",
        "        gnum = np.argmax(diff>0)\n",
        "        if gnum==0:\n",
        "          g_idx = index\n",
        "        else:\n",
        "          g_idx = index-self.cumsum[gnum-1]\n",
        "        # subset_x, subset_y  = self.gnum_subsets[gnum]\n",
        "        return torch.from_numpy(self.gnum_subsets[gnum][0].to_numpy())[g_idx:g_idx+self.window].float(), torch.from_numpy(self.gnum_subsets[gnum][1])[g_idx+self.window].float()"
      ],
      "metadata": {
        "id": "pcMpoW8c9sS9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SlowSequenceDataset(Dataset):\n",
        "    def __init__(self, data_x, data_y, window=30):\n",
        "        # self.x = torch.from_numpy(data_x)\n",
        "        # self.y = torch.from_numpy(data_y)\n",
        "        cols = [col for col in data_x.columns if col[0]!='V']\n",
        "        data_cols = [col for col in data_x.columns]\n",
        "        data_cols.remove(\"OCCUPANCY_DATE\")\n",
        "        self.data_cols = data_cols\n",
        "        cols.remove(\"OCCUPANCY_DATE\")\n",
        "        cols.remove(\"SERVICE_USER_COUNT\")\n",
        "        cols.remove(\"MONTH\")\n",
        "        cols.remove(\"DAY\")\n",
        "        data_x[\"GNUM\"] = data_x.groupby(cols).ngroup()\n",
        "        data_x[\"LOG_CNT\"] = data_y\n",
        "        data_x['index_col'] = list(data_x.index)\n",
        "        self.x = data_x\n",
        "        self.cumsum = np.cumsum(np.clip((data_x.groupby(\"GNUM\").count()[\"OCCUPANCY_DATE\"].to_numpy() - window), a_min=0, a_max=None))\n",
        "        self.length = self.cumsum[-1]\n",
        "        self.window = window\n",
        "        # self.gnum_subsets = []\n",
        "        # for gnum in self.x[\"GNUM\"]:\n",
        "        #     subset = self.x[self.x[\"GNUM\"]==gnum]\n",
        "        #     self.gnum_subsets.append((subset[self.data_cols],))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        diff = self.cumsum-index\n",
        "        gnum = np.argmax(diff>0)\n",
        "        if gnum==0:\n",
        "          g_idx = index\n",
        "        else:\n",
        "          g_idx = index-self.cumsum[gnum-1]\n",
        "        subset = self.x[self.x[\"GNUM\"]==gnum]\n",
        "        # print(subset[\"index_col\"])\n",
        "        return torch.from_numpy(subset[self.data_cols].to_numpy())[g_idx:g_idx+self.window].float(), torch.from_numpy(np.expand_dims(subset[\"LOG_CNT\"].to_numpy(), axis=-1))[g_idx+self.window].float(), subset[\"index_col\"].to_numpy()[g_idx+self.window], subset.iloc[g_idx:g_idx+self.window]\n",
        "        # subset_x, subset_y  = self.gnum_subsets[gnum]\n",
        "        # return torch.from_numpy(self.gnum_subsets[gnum][0].to_numpy())[g_idx:g_idx+self.window].float(), torch.from_numpy(self.gnum_subsets[gnum][1])[g_idx+self.window].float()\n",
        "    def get_gid(self, index):\n",
        "        diff = self.cumsum-index\n",
        "        gnum = np.argmax(diff>0)\n",
        "        if gnum==0:\n",
        "          g_idx = index\n",
        "        else:\n",
        "          g_idx = index-self.cumsum[gnum-1]\n",
        "        return g_idx\n",
        "\n",
        "    def get_df(self):\n",
        "        return self.x\n",
        "\n",
        "    def get_gnum(self, index):\n",
        "        diff = self.cumsum-index\n",
        "        gnum = np.argmax(diff>0)\n",
        "        return gnum\n",
        "\n",
        "    def get_df_index(self, index):\n",
        "        gnum = self.get_gnum(index)\n",
        "        gidx = self.get_gid(index)\n",
        "        subset = self.x[self.x[\"GNUM\"]==gnum]\n",
        "        return subset[\"index_col\"][gidx+self.window]"
      ],
      "metadata": {
        "id": "3usrIdJN4MOe"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_eval('/content/trans_model_log.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NvvI0eBgsJBq",
        "outputId": "4759dba8-8b6a-4dff-a903-477590ae453a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-dd981977055a>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-26-dd981977055a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-26-dd981977055a>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape 131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/26358 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     OCCUPANCY_DATE  SHELTER_ID  LOCATION_ID  SERVICE_USER_COUNT        V0  \\\n",
            "71       2023-01-01   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "178      2023-01-02   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "285      2023-01-03   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "392      2023-01-04   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "499      2023-01-05   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "606      2023-01-06   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "713      2023-01-07   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "820      2023-01-08   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "927      2023-01-09   -1.307519     -1.26052            0.064804 -1.327764   \n",
            "1034     2023-01-10   -1.307519     -1.26052            0.044570 -1.327764   \n",
            "1141     2023-01-11   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "1248     2023-01-12   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "1358     2023-01-13   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "1468     2023-01-14   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "1578     2023-01-15   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "1686     2023-01-16   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "1794     2023-01-17   -1.307519     -1.26052            0.004103 -1.327764   \n",
            "1902     2023-01-18   -1.307519     -1.26052            0.024336 -1.327764   \n",
            "2009     2023-01-19   -1.307519     -1.26052            0.085037 -1.327764   \n",
            "2116     2023-01-20   -1.307519     -1.26052            0.085037 -1.327764   \n",
            "2223     2023-01-21   -1.307519     -1.26052            0.085037 -1.327764   \n",
            "2330     2023-01-22   -1.307519     -1.26052            0.085037 -1.327764   \n",
            "2437     2023-01-23   -1.307519     -1.26052            0.085037 -1.327764   \n",
            "2544     2023-01-24   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "2654     2023-01-25   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "2764     2023-01-26   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "2873     2023-01-27   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "2982     2023-01-28   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "3091     2023-01-29   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "3200     2023-01-30   -1.307519     -1.26052            0.105271 -1.327764   \n",
            "\n",
            "            V1        V2        V3        V4        V5  ...  SECTOR_Men  \\\n",
            "71   -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "178  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "285  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "392  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "499  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "606  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "713  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "820  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "927  -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1034 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1141 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1248 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1358 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1468 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1578 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1686 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1794 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "1902 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2009 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2116 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2223 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2330 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2437 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2544 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2654 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2764 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2873 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "2982 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "3091 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "3200 -0.368198 -0.694422  0.025953  0.628374 -0.587932  ...    1.649872   \n",
            "\n",
            "      SECTOR_Mixed Adult  SECTOR_Women  SECTOR_Youth  prog_mod  cap_type  \\\n",
            "71             -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "178            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "285            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "392            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "499            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "606            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "713            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "820            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "927            -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1034           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1141           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1248           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1358           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1468           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1578           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1686           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1794           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "1902           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2009           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2116           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2223           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2330           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2437           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2544           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2654           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2764           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2873           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "2982           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "3091           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "3200           -0.605255     -0.462988     -0.460592  0.528793   0.60044   \n",
            "\n",
            "      GNUM   LOG_CNT  index_col  UNSCALED_SC  \n",
            "71       0  3.912023         71           50  \n",
            "178      0  3.912023        178           50  \n",
            "285      0  3.912023        285           50  \n",
            "392      0  3.912023        392           50  \n",
            "499      0  3.912023        499           50  \n",
            "606      0  3.912023        606           50  \n",
            "713      0  3.912023        713           50  \n",
            "820      0  3.912023        820           50  \n",
            "927      0  3.871201        927           48  \n",
            "1034     0  3.850148       1034           47  \n",
            "1141     0  3.828641       1141           46  \n",
            "1248     0  3.828641       1248           46  \n",
            "1358     0  3.828641       1358           46  \n",
            "1468     0  3.828641       1468           46  \n",
            "1578     0  3.828641       1578           46  \n",
            "1686     0  3.828641       1686           46  \n",
            "1794     0  3.806662       1794           45  \n",
            "1902     0  3.828641       1902           46  \n",
            "2009     0  3.891820       2009           49  \n",
            "2116     0  3.891820       2116           49  \n",
            "2223     0  3.891820       2223           49  \n",
            "2330     0  3.891820       2330           49  \n",
            "2437     0  3.891820       2437           49  \n",
            "2544     0  3.912023       2544           50  \n",
            "2654     0  3.912023       2654           50  \n",
            "2764     0  3.912023       2764           50  \n",
            "2873     0  3.912023       2873           50  \n",
            "2982     0  3.912023       2982           50  \n",
            "3091     0  3.912023       3091           50  \n",
            "3200     0  3.912023       3200           50  \n",
            "\n",
            "[30 rows x 136 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-193e027022e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/trans_model_log.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-61-a7edb9f6658b>\u001b[0m in \u001b[0;36mopen_eval\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malt_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"UNSCALED_SC\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mvalidated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \"\"\"\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"requires_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 )\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     def _validate_data(\n",
            "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- UNSCALED_SC\nFeature names seen at fit time, yet now missing:\n- SERVICE_USER_COUNT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TimeModel(140,\n",
        "                      hidden_dim=512,\n",
        "                      num_layers=2,\n",
        "                      num_heads=4,\n",
        "                      output_dim=1,\n",
        "                      seq_len=30)\n",
        "x = torch.randn((128, 30, 140))\n",
        "print(model)\n",
        "print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB3S8mdMrkAt",
        "outputId": "c5fe5404-a9cf-49dd-eb45-ebe851dc205b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeModel(\n",
            "  (fc0): Linear(in_features=140, out_features=256, bias=True)\n",
            "  (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (positional_encoding): PositionalEncoding()\n",
            "  (encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (dropout): Dropout(p=0.3, inplace=False)\n",
            "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.3, inplace=False)\n",
            "        (dropout2): Dropout(p=0.3, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (fc_dec): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc_dec2): Linear(in_features=256, out_features=32, bias=True)\n",
            "  (fc): Linear(in_features=960, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "torch.Size([128, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_sequence_data(data_path):\n",
        "    all_shelter_data = pd.read_csv(data_path, low_memory=False)\n",
        "    all_shelter_data['OCCUPANCY_DATE'] = pd.to_datetime(all_shelter_data['OCCUPANCY_DATE'])\n",
        "    toronto_data = all_shelter_data[all_shelter_data[\"LOCATION_CITY\"] == \"Toronto\"]\n",
        "    toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
        "    toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
        "    toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n",
        "    # df[df[\"LOCATION_CITY\"]==\"Toronto\"].groupby([\"OCCUPANCY_DATE\", \"LOCATION_ID\", \"SHELTER_ID\", \"SECTOR\", \"PROGRAM_MODEL\", \"CAPACITY_TYPE\"])\n",
        "    drop_cols = ['_id', 'ORGANIZATION_ID', 'ORGANIZATION_NAME', 'SHELTER_GROUP',\n",
        "                 'LOCATION_NAME', 'LOCATION_ADDRESS', 'LOCATION_CITY', 'LOCATION_PROVINCE', 'PROGRAM_ID',\n",
        "                 'PROGRAM_NAME', 'OVERNIGHT_SERVICE_TYPE', 'PROGRAM_AREA', 'CAPACITY_FUNDING_BED',\n",
        "                 'OCCUPIED_BEDS', 'UNOCCUPIED_BEDS', 'CAPACITY_FUNDING_ROOM', 'OCCUPIED_ROOMS', 'UNOCCUPIED_ROOMS',\n",
        "                 'OCCUPANCY_RATE_ROOMS', \"OCCUPANCY_RATE_BEDS\", 'UNAVAILABLE_BEDS','UNAVAILABLE_ROOMS',\n",
        "                 \"LOCATION_POSTAL_CODE\", \"Neighbourhood\", \"Neighbourhood Number\", 'LAT', 'LON',\n",
        "                 'CAPACITY_ACTUAL_BED', 'CAPACITY_ACTUAL_ROOM'\n",
        "                 ]\n",
        "    toronto_data_dr = toronto_data.drop(columns=drop_cols)\n",
        "    toronto_data_dr_nan = toronto_data_dr[toronto_data_dr[\"PROGRAM_MODEL\"].notna()]\n",
        "    # Creating list of dummy columns\n",
        "    to_get_dummies_for = ['SECTOR']\n",
        "    # Creating dummy variables\n",
        "    toronto_data_dr_nan = pd.get_dummies(data=toronto_data_dr_nan, columns=to_get_dummies_for)\n",
        "\n",
        "    # Mapping overtime and attrition\n",
        "    dict_prog_mod = {'Emergency': 1, 'Transitional': 0}\n",
        "    dict_cap_type = {'Bed Based Capacity': 1, 'Room Based Capacity': 0}\n",
        "\n",
        "    toronto_data_dr_nan['prog_mod'] = toronto_data_dr_nan[\"PROGRAM_MODEL\"].map(dict_prog_mod)\n",
        "    toronto_data_dr_nan['cap_type'] = toronto_data_dr_nan[\"CAPACITY_TYPE\"].map(dict_cap_type)\n",
        "    toronto_data_dr_nan = toronto_data_dr_nan.drop(columns=[\"PROGRAM_MODEL\", \"CAPACITY_TYPE\"])\n",
        "\n",
        "\n",
        "    final_df = toronto_data_dr_nan\n",
        "    occu_final_df = toronto_data_dr_nan\n",
        "    occu_final_df = occu_final_df[occu_final_df['YEAR']==2023]\n",
        "    info = {\"test_dated\": occu_final_df.reset_index(drop=True)}\n",
        "    final_df = final_df.fillna(value=0.0)\n",
        "    test = final_df[final_df['YEAR']==2023]\n",
        "    train = final_df[(final_df['YEAR']==2021) | (final_df['YEAR']==2022)]\n",
        "    train = train.drop(columns=['YEAR'])\n",
        "    test = test.drop(columns=['YEAR'])\n",
        "    X_train, X_test, y_train, y_test = train, test, train['SERVICE_USER_COUNT'], test['SERVICE_USER_COUNT']\n",
        "    sc = StandardScaler()\n",
        "    # print(list(X_train.select_dtypes(include=['object']).columns))\n",
        "    # Fit_transform on train data\n",
        "    cols = list(X_train.columns)\n",
        "    cols.remove(\"OCCUPANCY_DATE\")\n",
        "    X_train[cols] = sc.fit_transform(X_train[cols])\n",
        "\n",
        "    # Transform on test data\n",
        "    X_test[cols] = sc.transform(X_test[cols])\n",
        "    info[\"scaler\"] = sc\n",
        "\n",
        "    return X_train.reset_index(drop=True), X_test.reset_index(drop=True), y_train.reset_index(drop=True), y_test.reset_index(drop=True), info"
      ],
      "metadata": {
        "id": "cR_XOHBcbEeq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_seq():\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, info = load_sequence_data(combined_data_path)\n",
        "    train_dataset = SlowSequenceDataset(X_train_scaled, np.log(np.asarray(y_train)))\n",
        "    test_dataset = SlowSequenceDataset(X_test_scaled, np.log(np.asarray(y_test)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[1]\n",
        "    print(f\"input shape {input_shape}\")\n",
        "    model = TimeModel(input_shape,\n",
        "                      hidden_dim=512,\n",
        "                      num_layers=1,\n",
        "                      num_heads=4,\n",
        "                      output_dim=1,\n",
        "                      seq_len=30).to(\"cuda\")\n",
        "    train_dataloader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "    test_dataloader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-5)\n",
        "    model, history = train(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        train_dataloader,\n",
        "        test_dataloader,\n",
        "        save_file_name='./trans_model_log.pt',\n",
        "        max_epochs_stop=50,\n",
        "        n_epochs=100,\n",
        "        print_every=1)\n",
        "\n",
        "    plot_loss(history, \"./loss.jpg\")\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "i8R-uHNf22zA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_seq()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O2ITWG5unybk",
        "outputId": "d780244c-488f-4266-f078-fade6679ad8d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-0b26a8a686e1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-14-0b26a8a686e1>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-14-0b26a8a686e1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape 131\n",
            "Starting Training from Scratch.\n",
            "\n",
            "\n",
            "Epoch: 0 \tTraining Loss: 2.9039 \tValidation Loss: 0.7654\n",
            "\n",
            "Epoch: 1 \tTraining Loss: 0.4347 \tValidation Loss: 0.5582\n",
            "\n",
            "Epoch: 2 \tTraining Loss: 0.2559 \tValidation Loss: 0.3484\n",
            "\n",
            "Epoch: 3 \tTraining Loss: 0.2129 \tValidation Loss: 0.3064\n",
            "\n",
            "Epoch: 4 \tTraining Loss: 0.1930 \tValidation Loss: 0.2867\n",
            "\n",
            "Epoch: 5 \tTraining Loss: 0.1760 \tValidation Loss: 0.2600\n",
            "\n",
            "Epoch: 6 \tTraining Loss: 0.1657 \tValidation Loss: 0.2537\n",
            "\n",
            "Epoch: 7 \tTraining Loss: 0.1534 \tValidation Loss: 0.2311\n",
            "\n",
            "Epoch: 8 \tTraining Loss: 0.1420 \tValidation Loss: 0.2157\n",
            "\n",
            "Epoch: 9 \tTraining Loss: 0.1299 \tValidation Loss: 0.1959\n",
            "\n",
            "Epoch: 10 \tTraining Loss: 0.1187 \tValidation Loss: 0.1826\n",
            "\n",
            "Epoch: 11 \tTraining Loss: 0.1094 \tValidation Loss: 0.1889\n",
            "\n",
            "Epoch: 12 \tTraining Loss: 0.1030 \tValidation Loss: 0.1748\n",
            "\n",
            "Epoch: 13 \tTraining Loss: 0.0992 \tValidation Loss: 0.1724\n",
            "\n",
            "Epoch: 14 \tTraining Loss: 0.0964 \tValidation Loss: 0.1718\n",
            "\n",
            "Epoch: 15 \tTraining Loss: 0.0925 \tValidation Loss: 0.1671\n",
            "\n",
            "Epoch: 16 \tTraining Loss: 0.0900 \tValidation Loss: 0.1807\n",
            "\n",
            "Epoch: 17 \tTraining Loss: 0.0882 \tValidation Loss: 0.1833\n",
            "\n",
            "Epoch: 18 \tTraining Loss: 0.0864 \tValidation Loss: 0.1778\n",
            "\n",
            "Epoch: 19 \tTraining Loss: 0.0841 \tValidation Loss: 0.1819\n",
            "\n",
            "Epoch: 20 \tTraining Loss: 0.0821 \tValidation Loss: 0.1753\n",
            "\n",
            "Epoch: 21 \tTraining Loss: 0.0803 \tValidation Loss: 0.1820\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-dea7ab4fc85b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-4491f28f9533>\u001b[0m in \u001b[0;36mtrain_seq\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     model, history = train(\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-915c89264a61>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, valid_loader, save_file_name, max_epochs_stop, n_epochs, print_every)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;31m# Tensors to gpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtrain_on_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-456b7a0cec2a>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m           \u001b[0mg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgnum\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GNUM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LOG_CNT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# subset_x, subset_y  = self.gnum_subsets[gnum]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3851\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3852\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \"\"\"\n\u001b[0;32m-> 3902\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3886\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3887\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m         return self.reindex_indexer(\n\u001b[0m\u001b[1;32m    979\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_refs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             new_blocks = [\n\u001b[0m\u001b[1;32m    752\u001b[0m                 blk.take_nd(\n\u001b[1;32m    753\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             new_blocks = [\n\u001b[0;32m--> 752\u001b[0;31m                 blk.take_nd(\n\u001b[0m\u001b[1;32m    753\u001b[0m                     \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0;31m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_take_nd_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/array_algos/take.py\u001b[0m in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "def open_eval(model_path):\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, info = load_sequence_data(combined_data_path)\n",
        "    cols = list(X_train_scaled.columns)\n",
        "    cols.remove(\"OCCUPANCY_DATE\")\n",
        "    train_dataset = SlowSequenceDataset(X_train_scaled, np.log(np.asarray(y_train)))\n",
        "    test_dataset = SlowSequenceDataset(X_test_scaled, np.log(np.asarray(y_test)))\n",
        "\n",
        "    x, y, _, _ = train_dataset[10]\n",
        "    input_shape = x.shape[1]\n",
        "    print(f\"input shape {input_shape}\")\n",
        "    model = TimeModel(input_shape,\n",
        "                      hidden_dim=512,\n",
        "                      num_layers=1,\n",
        "                      num_heads=4,\n",
        "                      output_dim=1,\n",
        "                      seq_len=30).to(\"cuda\")\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    sc = info[\"scaler\"]\n",
        "    alt_cols = list(map(lambda x: x.replace('SERVICE_USER_COUNT', 'UNSCALED_SC'), cols))\n",
        "    test_dataset.x[\"UNSCALED_SC\"] = y_test\n",
        "    for i in tqdm.tqdm(range(len(test_dataset))):\n",
        "        _, _, idx, ss = test_dataset[i]\n",
        "        ss[cols] = sc.inverse_transform(ss[cols])\n",
        "        ss = ss.drop(columns=[\"SERVICE_USER_COUNT\"])\n",
        "        ss = ss.rename(columns={\"UNSCALED_SC\": \"SERVICE_USER_COUNT\"})\n",
        "        input = sc.transform(ss[cols])\n",
        "        y_pred = model(torch.unsqueeze(torch.from_numpy(input), dim=0).to(\"cuda\").float())\n",
        "        test_dataset.x[\"UNSCALED_SC\", idx] = np.exp(torch.squeeze(y_pred.detach()).to(\"cpu\").item())\n",
        "    test_dataset.x[\"ACTUAL\"] = y_test\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(test_dataset.x.groupby('OCCUPANCY_DATE')['ACTUAL'].sum())\n",
        "    plt.plot(test_dataset.x.groupby('OCCUPANCY_DATE')['UNSCALED_SC'].sum())\n",
        "    plt.legend(['Actual', 'Predicted'])\n",
        "    plt.xlabel('Day')\n",
        "    plt.ylabel('Average user count')\n",
        "    plt.title('Evaluation of predicted user counts')\n",
        "    plt.savefig('./trans_model_eval.jpg')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def closed_eval(model_path):\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, df_copy = load_sequence_data(combined_data_path)\n",
        "    train_dataset = DefaultDataset(X_train_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_train), axis=-1)))\n",
        "    test_dataset = DefaultDataset(X_test_scaled.to_numpy(), np.log(np.expand_dims(np.asarray(y_test), axis=-1)))\n",
        "\n",
        "    x, y = train_dataset[10]\n",
        "    input_shape = x.shape[0]\n",
        "    model = MLP(input_shape, 1)\n",
        "    model.eval()\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    y_pred = model(torch.from_numpy(X_test_scaled.to_numpy()).float())\n",
        "    y_pred = y_pred.detach().numpy()\n",
        "    y_pred = np.squeeze(np.exp(y_pred))\n",
        "    # df_copy['PRED_SC'] = y_pred\n",
        "    # plt.figure(figsize=(8, 6))\n",
        "    # plt.plot(df_copy.groupby('OCCUPANCY_DATE')['SERVICE_USER_COUNT'].sum())\n",
        "    # plt.plot(df_copy.groupby('OCCUPANCY_DATE')['PRED_SC'].sum())\n",
        "    # plt.legend(['Actual', 'Predicted'])\n",
        "    # plt.xlabel('Day')\n",
        "    # plt.ylabel('Average user count')\n",
        "    # plt.title('Evaluation of predicted user counts')\n",
        "    # plt.savefig('./mlp_model_log_loc_feat_shelid_cap_eval.jpg')\n"
      ],
      "metadata": {
        "id": "h3m6kfdMN0vP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_eval('/content/trans_model_log.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hRKBax13oPPM",
        "outputId": "0a73b096-8245-4c47-df79-cd420cec95ec"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-dd981977055a>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-26-dd981977055a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-26-dd981977055a>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape 131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 652/26358 [01:18<1:10:55,  6.04it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  3%|▎         | 670/26358 [01:21<1:12:03,  5.94it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  4%|▍         | 1013/26358 [02:29<1:48:05,  3.91it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  5%|▍         | 1257/26358 [03:32<1:53:52,  3.67it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  5%|▌         | 1324/26358 [03:51<1:56:46,  3.57it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  5%|▌         | 1358/26358 [04:02<2:03:26,  3.38it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1473/26358 [04:37<2:07:33,  3.25it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1479/26358 [04:38<2:07:13,  3.26it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1483/26358 [04:40<2:06:47,  3.27it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1486/26358 [04:41<2:06:24,  3.28it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1504/26358 [04:47<2:16:07,  3.04it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1507/26358 [04:48<2:10:06,  3.18it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▌         | 1623/26358 [05:26<2:14:58,  3.05it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  6%|▋         | 1692/26358 [05:50<2:21:28,  2.91it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  7%|▋         | 1931/26358 [07:20<2:37:48,  2.58it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  8%|▊         | 2046/26358 [08:09<2:43:45,  2.47it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  8%|▊         | 2121/26358 [08:41<2:47:17,  2.41it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  8%|▊         | 2208/26358 [09:19<2:59:45,  2.24it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  9%|▊         | 2248/26358 [09:38<3:01:08,  2.22it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  9%|▊         | 2301/26358 [10:03<3:22:42,  1.98it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  9%|▊         | 2303/26358 [10:03<3:16:02,  2.05it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            "  9%|▊         | 2305/26358 [10:04<3:10:01,  2.11it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|▉         | 2608/26358 [12:35<3:29:45,  1.89it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|▉         | 2614/26358 [12:38<3:21:56,  1.96it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|█         | 2637/26358 [12:50<3:25:11,  1.93it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|█         | 2649/26358 [12:56<3:20:52,  1.97it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|█         | 2667/26358 [13:06<3:30:08,  1.88it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|█         | 2757/26358 [13:55<3:30:40,  1.87it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 10%|█         | 2761/26358 [13:57<3:29:13,  1.88it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 11%|█         | 2786/26358 [14:11<3:32:05,  1.85it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 11%|█         | 2790/26358 [14:13<3:28:51,  1.88it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 11%|█         | 2806/26358 [14:22<3:33:19,  1.84it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 11%|█         | 2855/26358 [14:50<3:56:34,  1.66it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 13%|█▎        | 3425/26358 [21:19<4:02:54,  1.57it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 13%|█▎        | 3451/26358 [21:36<4:04:43,  1.56it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 13%|█▎        | 3514/26358 [22:18<4:06:45,  1.54it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 14%|█▍        | 3653/26358 [23:53<4:15:12,  1.48it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 14%|█▍        | 3809/26358 [25:44<4:52:08,  1.29it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 14%|█▍        | 3812/26358 [25:46<4:33:03,  1.38it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 15%|█▌        | 4003/26358 [28:07<4:31:03,  1.37it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 16%|█▌        | 4097/26358 [29:18<4:40:25,  1.32it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 16%|█▌        | 4137/26358 [29:49<4:45:15,  1.30it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 16%|█▌        | 4191/26358 [30:32<5:30:40,  1.12it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 17%|█▋        | 4444/26358 [33:56<4:56:22,  1.23it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 18%|█▊        | 4677/26358 [37:11<5:07:25,  1.18it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 18%|█▊        | 4687/26358 [37:20<5:28:18,  1.10it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 19%|█▉        | 4981/26358 [42:17<5:45:41,  1.03it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 19%|█▉        | 5041/26358 [43:15<6:55:12,  1.17s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 20%|██        | 5277/26358 [46:59<5:48:24,  1.01it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 20%|██        | 5390/26358 [48:49<5:37:44,  1.03it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 21%|██        | 5464/26358 [50:02<5:40:33,  1.02it/s]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 21%|██▏       | 5609/26358 [52:29<6:02:48,  1.05s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 22%|██▏       | 5765/26358 [55:10<5:48:40,  1.02s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 22%|██▏       | 5787/26358 [55:33<6:04:15,  1.06s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 23%|██▎       | 6051/26358 [1:00:18<6:20:06,  1.12s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 23%|██▎       | 6180/26358 [1:02:41<6:16:55,  1.12s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 24%|██▍       | 6416/26358 [1:07:11<6:22:03,  1.15s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 25%|██▍       | 6494/26358 [1:08:41<6:20:25,  1.15s/it]<ipython-input-79-3a9f55d67775>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ss[cols] = sc.inverse_transform(ss[cols])\n",
            " 26%|██▌       | 6723/26358 [1:13:15<3:33:58,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-193e027022e7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopen_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/trans_model_log.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-3a9f55d67775>\u001b[0m in \u001b[0;36mopen_eval\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"UNSCALED_SC\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SERVICE_USER_COUNT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-dc06c0a649be>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0mg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgnum\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"GNUM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# print(subset[\"index_col\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"LOG_CNT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index_col\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mg_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3851\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3852\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3855\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3900\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3901\u001b[0m         \"\"\"\n\u001b[0;32m-> 3902\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3903\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3904\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3882\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3883\u001b[0m         \"\"\"\n\u001b[0;32m-> 3884\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3886\u001b[0m         new_data = self._mgr.take(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5978\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5980\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5982\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5966\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5967\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5968\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5969\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5970\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5977\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5978\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5980\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconsolidate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1870\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1871\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1872\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_consolidate_with_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[0mnew_blocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m         merged_blocks, _ = _merge_blocks(\n\u001b[0m\u001b[1;32m   2330\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   2379\u001b[0m             \u001b[0;31m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m             \u001b[0;31m# Sequence[Sequence[Any]], SupportsArray]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2381\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m             \u001b[0mbvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled, X_test_scaled, y_train, y_test, info = load_sequence_data(combined_data_path)\n",
        "cols = [col for col in X_train_scaled.columns if col[0]!='V']\n",
        "print(cols)"
      ],
      "metadata": {
        "id": "xGIEuXmL9hCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b23bf7-84c5-4e3d-df68-4b547c03546b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-0b26a8a686e1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-10-0b26a8a686e1>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-10-0b26a8a686e1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['OCCUPANCY_DATE', 'SHELTER_ID', 'LOCATION_ID', 'SERVICE_USER_COUNT', 'MONTH', 'DAY', 'SECTOR_Families', 'SECTOR_Men', 'SECTOR_Mixed Adult', 'SECTOR_Women', 'SECTOR_Youth', 'prog_mod', 'cap_type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols.remove(\"OCCUPANCY_DATE\")\n",
        "cols.remove(\"SERVICE_USER_COUNT\")\n",
        "cols.remove(\"MONTH\")\n",
        "cols.remove(\"DAY\")"
      ],
      "metadata": {
        "id": "XP36A2_nzNfD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[\"GNUM\"] = X_train_scaled.groupby(cols).ngroup()"
      ],
      "metadata": {
        "id": "S2tRrwizbC2Y"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train_scaled.groupby(\"GNUM\").count()[\"OCCUPANCY_DATE\"]-30).cumsum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7SrkSaRdcEw",
        "outputId": "0b9c03cb-f4e5-4d98-9a00-281430d71d9d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GNUM\n",
              "0        700\n",
              "1       1400\n",
              "2       2100\n",
              "3       2520\n",
              "4       3679\n",
              "       ...  \n",
              "129    73553\n",
              "130    73601\n",
              "131    73616\n",
              "132    73814\n",
              "133    73790\n",
              "Name: OCCUPANCY_DATE, Length: 134, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cumsum = np.cumsum(np.clip((X_train_scaled.groupby(\"GNUM\").count()[\"OCCUPANCY_DATE\"].to_numpy() - 30), a_min=0, a_max=None))"
      ],
      "metadata": {
        "id": "4f3FBQW7bRdX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled, X_test_scaled, y_train, y_test, info = load_sequence_data(combined_data_path)\n",
        "train_dataset = SlowSequenceDataset(X_train_scaled, np.log(np.asarray(y_train)))\n",
        "test_dataset = SlowSequenceDataset(X_test_scaled, np.log(np.asarray(y_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBT_u0M3hRGA",
        "outputId": "24ea1dde-dff3-4b92-be97-a04e3e8e4cf4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-0b26a8a686e1>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['MONTH'] = toronto_data['OCCUPANCY_DATE'].dt.month\n",
            "<ipython-input-14-0b26a8a686e1>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['DAY'] = toronto_data['OCCUPANCY_DATE'].dt.day\n",
            "<ipython-input-14-0b26a8a686e1>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  toronto_data['YEAR'] = toronto_data['OCCUPANCY_DATE'].dt.year\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(cumsum-66718)>0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saIugF4jgoDI",
        "outputId": "a1bfa26d-4815-4ccb-ae2b-23c4e79bb546"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}